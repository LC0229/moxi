# Moxi Configuration
# Copy this file to .env and fill in your API keys

# Project Info
PROJECT_NAME=moxi
ENVIRONMENT=development

# OpenAI API (for dataset generation)
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL_ID=gpt-4o-mini

# GitHub Token (for repo crawling)
GITHUB_TOKEN=your_github_token_here

# Hugging Face (for model training/inference)
HUGGINGFACE_ACCESS_TOKEN=your_huggingface_token_here
MODEL_ID=meta-llama/Llama-3.1-8B-Instruct

# Training Configuration
MAX_INPUT_TOKENS=2048
MAX_OUTPUT_TOKENS=1024
MAX_TOTAL_TOKENS=3072

# Embeddings (optional, for future RAG features)
EMBEDDING_MODEL_ID=BAAI/bge-small-en-v1.5
EMBEDDING_SIZE=384
EMBEDDING_MODEL_DEVICE=cpu

# MongoDB (same pattern as llm-twin-course; llm-twin uses LOCAL Docker Mongo by default)
# Option A - Local (no TLS): run "docker compose up -d mongodb" then use:
# MONGODB_URI=mongodb://moxi:moxi@localhost:27017
# MONGODB_DB_NAME=moxi
# Option B - Atlas: set MONGODB_URI to your mongodb+srv://... (may hit SSL on some Macs; see docs/MONGODB_SETUP.md)
# MONGODB_URI=mongodb+srv://...
# MONGODB_DB_NAME=moxi

# Experiment Tracking (optional)
# WANDB_API_KEY=your_wandb_api_key_here
# WANDB_PROJECT=moxi
# COMET_API_KEY=your_comet_api_key_here
# COMET_WORKSPACE=your_workspace
# COMET_PROJECT=moxi

# AWS Config (optional, for cloud deployment)
# AWS_REGION=us-east-1
# AWS_ACCESS_KEY=your_aws_access_key
# AWS_SECRET_KEY=your_aws_secret_key
# AWS_ARN_ROLE=your_arn_role

# Dataset Generation
MIN_REPO_STARS=100
MAX_REPOS_TO_CRAWL=100
DATASET_SIZE=10000
